{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .', {'entities': [(48, 54, 'GEO'), (77, 81, 'GEO'), (111, 118, 'GPE')]})\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import ast\n",
    "from spacy.training.example import Example\n",
    "\n",
    "# load the training dataset\n",
    "import pandas as pd\n",
    "training_data_file_path = \"/Users/shubham/Desktop/ner.csv\"\n",
    "\n",
    "# read csv into pandas DataFrame\n",
    "df = pd.read_csv(training_data_file_path)\n",
    "# Grab any basic information df.head() or: Summary statistics, Access a specific column, etc...\n",
    "\n",
    "'''\n",
    "One thing to note here: is that this NER dataset that I found is split into the following columns:\n",
    "    - Sentence #, Sentence, POS(Word type description, NOUN, etc..), Tag(O-per with IOB-named entity)\n",
    "But spaCy doesn't understand the data in this format spaCy understands data in the format of a tuple\n",
    "    - (string, dict) where dict = {entities : [tuples of character indices of the start of the token(start, end, + IOB-named entity)]}\n",
    "So in order to train the model with spaCy like the paper suggests we first need to reformat the dataFrame to match\n",
    "into this form which is what convert_to_spacy is doing\n",
    "'''\n",
    "def convert_to_spacy_Part_One(df):\n",
    "    tagged_spacy_data = []\n",
    "    for index, row in df.iterrows():\n",
    "        sentence = row['Sentence']\n",
    "        ner_tags = row['Tag']\n",
    "\n",
    "        # right now here ner_tags is of type string, so in order to get the elements lets convert to a list\n",
    "        ner_tags = ast.literal_eval(ner_tags)\n",
    "\n",
    "        entities = []\n",
    "        start = 0\n",
    "        end = 0\n",
    "        for tagIndex, word in enumerate(sentence.split()):\n",
    "            end = start + len(word)\n",
    "\n",
    "            if tagIndex >= len(ner_tags): \n",
    "                break\n",
    "            if(ner_tags[tagIndex] != 'O'):\n",
    "                # print(f\"({start}, {end}, {ner_tags[tagIndex]} | {tagIndex}\")\n",
    "                entities.append((start, end, ner_tags[tagIndex]))\n",
    "\n",
    "            start = end + 1\n",
    "        \n",
    "        if len(entities) > 0:\n",
    "            tagged_spacy_data.append((sentence, {\"entities\": entities}))\n",
    "\n",
    "    return tagged_spacy_data\n",
    "\n",
    "'''\n",
    "So basically the convert_to_spacy_Part_One gives u an output like this:\n",
    "    ('The German firm works as a sub-contractor for Shell .', {'entities': [(4, 10, 'B-gpe'), (46, 51, 'B-org')]})\n",
    "When we train a spaCy Model we need the form to be like this:\n",
    "    ('The German firm works as a sub-contractor for Shell .', {'entities': [(4, 10, 'GPE'), (46, 51, 'ORG')]})\n",
    "So the function convert_to_spaCy_Part_Two will .upper() the string [2:]\n",
    "\n",
    "'''\n",
    "def convert_to_spacy_Part_Two(spacy_data):\n",
    "    spacy_formatted_data = []\n",
    "\n",
    "    for sentence, entities_dict in spacy_data:\n",
    "\n",
    "        entities_list = entities_dict[\"entities\"]\n",
    "        modified_entities = []\n",
    "\n",
    "        for start, end, type in entities_list:\n",
    "            currType = type\n",
    "            formattedType = currType[2:].upper() # take 'B-Geo' -> 'GEO'\n",
    "            modified_entities.append((start, end, formattedType))\n",
    "        \n",
    "        spacy_formatted_data.append((sentence, {\"entities\" : modified_entities}))\n",
    "\n",
    "    return spacy_formatted_data\n",
    "\n",
    "\n",
    "# Convert the DataFrame to spaCy format but still the tags are in there\n",
    "spacy_training_data = convert_to_spacy_Part_One(df)\n",
    "\n",
    "# remove the tags and now we are officially ready to train our model, spacy_formatted_data is a list of training data\n",
    "spacy_formatted_data = convert_to_spacy_Part_Two(spacy_training_data)\n",
    "\n",
    "print(spacy_formatted_data[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
