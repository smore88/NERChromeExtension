{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/shubham/anaconda3/lib/python3.11/site-packages (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from spacy) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/shubham/anaconda3/lib/python3.11/site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/shubham/anaconda3/lib/python3.11/site-packages (from jinja2->spacy) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Steps\n",
    "1. installed spacy and download the language model\n",
    "2. install nltk - this can be used to tokenize\n",
    "'''\n",
    "%pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Inc. - ORG\n",
      "Cupertino - GPE\n",
      "California - GPE\n",
      "Steve Jobs - PERSON\n"
     ]
    }
   ],
   "source": [
    "# Implement NER with spacy sample test\n",
    "import spacy\n",
    "\n",
    "# Load the spacy english model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample text\n",
    "text = \"Apple Inc. is a technology company based in Cupertino, California. It was founded by Steve Jobs.\"\n",
    "\n",
    "# Process the text with spaCy, this does tokenization for each \n",
    "# word(tells the text, part-of-speech, and dependency relation)\n",
    "# Ex: Apple PROPN compound\n",
    "doc = nlp(text)\n",
    "\n",
    "# testing what doc gives me\n",
    "# for token in doc:\n",
    "#     print(token.text, token.pos_, token.dep_, token.ent_iob_)\n",
    "\n",
    "# Print the named entities in the text\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} - {ent.label_}\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"[E022] Could not find a transition with the name 'O' in the NER model.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/shubham/ForwardDataLabTask1/Part2_Implementation.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shubham/ForwardDataLabTask1/Part2_Implementation.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):  \u001b[39m# Adjust the number of epochs as needed\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shubham/ForwardDataLabTask1/Part2_Implementation.ipynb#W2sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         \u001b[39mfor\u001b[39;00m example \u001b[39min\u001b[39;00m training_data:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/shubham/ForwardDataLabTask1/Part2_Implementation.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m             nlp\u001b[39m.\u001b[39mupdate([example], drop\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)  \u001b[39m# Adjust the dropout parameter\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shubham/ForwardDataLabTask1/Part2_Implementation.ipynb#W2sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Save the trained model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shubham/ForwardDataLabTask1/Part2_Implementation.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m nlp\u001b[39m.\u001b[39mto_disk(\u001b[39m\"\u001b[39m\u001b[39mcustom_ner_model\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/language.py:1193\u001b[0m, in \u001b[0;36mLanguage.update\u001b[0;34m(self, examples, _, drop, sgd, losses, component_cfg, exclude, annotates)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39mfor\u001b[39;00m name, proc \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpipeline:\n\u001b[1;32m   1191\u001b[0m     \u001b[39m# ignore statements are used here because mypy ignores hasattr\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mupdate\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1193\u001b[0m         proc\u001b[39m.\u001b[39mupdate(examples, sgd\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, losses\u001b[39m=\u001b[39mlosses, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcomponent_cfg[name])  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m     \u001b[39mif\u001b[39;00m sgd \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   1195\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1196\u001b[0m             name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude\n\u001b[1;32m   1197\u001b[0m             \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(proc, ty\u001b[39m.\u001b[39mTrainableComponent)\n\u001b[1;32m   1198\u001b[0m             \u001b[39mand\u001b[39;00m proc\u001b[39m.\u001b[39mis_trainable\n\u001b[1;32m   1199\u001b[0m             \u001b[39mand\u001b[39;00m proc\u001b[39m.\u001b[39mmodel \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   1200\u001b[0m         ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/pipeline/transition_parser.pyx:411\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.update\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/pipeline/transition_parser.pyx:671\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser._init_gold_batch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/pipeline/_parser_internals/ner.pyx:297\u001b[0m, in \u001b[0;36mspacy.pipeline._parser_internals.ner.BiluoPushDown.init_gold\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/pipeline/_parser_internals/ner.pyx:61\u001b[0m, in \u001b[0;36mspacy.pipeline._parser_internals.ner.BiluoGold.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/pipeline/_parser_internals/ner.pyx:89\u001b[0m, in \u001b[0;36mspacy.pipeline._parser_internals.ner.create_gold_state\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/pipeline/_parser_internals/ner.pyx:201\u001b[0m, in \u001b[0;36mspacy.pipeline._parser_internals.ner.BiluoPushDown.lookup_transition\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"[E022] Could not find a transition with the name 'O' in the NER model.\""
     ]
    }
   ],
   "source": [
    "# We want the named entities to be: PERSON, LOC, ORG, OTHER so using spacy we can train a model to work with\n",
    "# those entities, lets first give some training_data\n",
    "\n",
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "\n",
    "training_data = [\n",
    "    Example.from_dict(nlp.make_doc(\"Apple is a software engineering company.\"), {\"entities\" : [(0, 5, \"ORG\")]}),\n",
    "    Example.from_dict(nlp.make_doc(\"Shubham works at Apple in Maryland.\"), {\"entities\": [(0, 7, \"PERSON\"), (26, 34, \"LOC\")]}),\n",
    "]\n",
    "\n",
    "# load the spacy model and NER component that we will train this data with\n",
    "nlp = spacy.blank(\"en\")\n",
    "ner = nlp.add_pipe(\"ner\")\n",
    "\n",
    "# add the label_tags to the ner we are creating\n",
    "label_tags = [\"PERSON\", \"ORG\", \"LOC\", \"OTHER\"]\n",
    "for x in label_tags:\n",
    "    ner.add_label(x)\n",
    "\n",
    "# Disable other pipeline components during training for efficiency\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    # Training loop\n",
    "    for epoch in range(10):  # Adjust the number of epochs as needed\n",
    "        for example in training_data:\n",
    "            nlp.update([example], drop=0.5)  # Adjust the dropout parameter\n",
    "\n",
    "# Save the trained model\n",
    "nlp.to_disk(\"custom_ner_model\")\n",
    "\n",
    "\n",
    "\n",
    "# text = \"Apple Inc. is a technology company based in Cupertino, California. It was founded by Steve Jobs.\"\n",
    "# doc = nlp(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shubham/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"John works at XYZ Corp.\" with entities \"[(0, 4, 'PERSON'), (15, 22, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"[E022] Could not find a transition with the name 'O' in the NER model.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/shubham/ForwardDataLabTask1/Part2_Implementation.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shubham/ForwardDataLabTask1/Part2_Implementation.ipynb#W3sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):  \u001b[39m# Adjust the number of epochs as needed\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shubham/ForwardDataLabTask1/Part2_Implementation.ipynb#W3sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         \u001b[39mfor\u001b[39;00m example \u001b[39min\u001b[39;00m train_examples:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/shubham/ForwardDataLabTask1/Part2_Implementation.ipynb#W3sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m             nlp\u001b[39m.\u001b[39mupdate([example], drop\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)  \u001b[39m# Adjust the dropout parameter\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shubham/ForwardDataLabTask1/Part2_Implementation.ipynb#W3sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Save the trained model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shubham/ForwardDataLabTask1/Part2_Implementation.ipynb#W3sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m nlp\u001b[39m.\u001b[39mto_disk(\u001b[39m\"\u001b[39m\u001b[39mcustom_ner_model\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/language.py:1193\u001b[0m, in \u001b[0;36mLanguage.update\u001b[0;34m(self, examples, _, drop, sgd, losses, component_cfg, exclude, annotates)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39mfor\u001b[39;00m name, proc \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpipeline:\n\u001b[1;32m   1191\u001b[0m     \u001b[39m# ignore statements are used here because mypy ignores hasattr\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mupdate\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1193\u001b[0m         proc\u001b[39m.\u001b[39mupdate(examples, sgd\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, losses\u001b[39m=\u001b[39mlosses, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcomponent_cfg[name])  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m     \u001b[39mif\u001b[39;00m sgd \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   1195\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1196\u001b[0m             name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude\n\u001b[1;32m   1197\u001b[0m             \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(proc, ty\u001b[39m.\u001b[39mTrainableComponent)\n\u001b[1;32m   1198\u001b[0m             \u001b[39mand\u001b[39;00m proc\u001b[39m.\u001b[39mis_trainable\n\u001b[1;32m   1199\u001b[0m             \u001b[39mand\u001b[39;00m proc\u001b[39m.\u001b[39mmodel \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   1200\u001b[0m         ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/pipeline/transition_parser.pyx:411\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.update\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/pipeline/transition_parser.pyx:671\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser._init_gold_batch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/pipeline/_parser_internals/ner.pyx:297\u001b[0m, in \u001b[0;36mspacy.pipeline._parser_internals.ner.BiluoPushDown.init_gold\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/pipeline/_parser_internals/ner.pyx:61\u001b[0m, in \u001b[0;36mspacy.pipeline._parser_internals.ner.BiluoGold.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/pipeline/_parser_internals/ner.pyx:89\u001b[0m, in \u001b[0;36mspacy.pipeline._parser_internals.ner.create_gold_state\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/pipeline/_parser_internals/ner.pyx:201\u001b[0m, in \u001b[0;36mspacy.pipeline._parser_internals.ner.BiluoPushDown.lookup_transition\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"[E022] Could not find a transition with the name 'O' in the NER model.\""
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "\n",
    "# Create a blank English model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Add NER component to the pipeline\n",
    "ner = nlp.add_pipe(\"ner\")\n",
    "\n",
    "# Define your custom labels\n",
    "custom_labels = [\"PERSON\", \"LOC\", \"ORG\", \"OTHER\"]\n",
    "\n",
    "# Add custom labels to NER\n",
    "for label in custom_labels:\n",
    "    ner.add_label(label)\n",
    "\n",
    "# Example training data\n",
    "TRAIN_DATA = [\n",
    "    (\"John works at XYZ Corp.\", {\"entities\": [(0, 4, \"PERSON\"), (15, 22, \"ORG\")]}),\n",
    "    (\"Paris is a beautiful city.\", {\"entities\": [(0, 5, \"LOC\")]}),\n",
    "    # Add more examples as needed with PERSON, LOC, ORG, and OTHER entities\n",
    "]\n",
    "\n",
    "# Prepare training data as Example objects\n",
    "train_examples = []\n",
    "for text, annotations in TRAIN_DATA:\n",
    "    train_examples.append(Example.from_dict(nlp.make_doc(text), annotations))\n",
    "\n",
    "# Disable other pipeline components during training for efficiency\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    # Training loop\n",
    "    for epoch in range(10):  # Adjust the number of epochs as needed\n",
    "        for example in train_examples:\n",
    "            nlp.update([example], drop=0.5)  # Adjust the dropout parameter\n",
    "\n",
    "# Save the trained model\n",
    "nlp.to_disk(\"custom_ner_model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
