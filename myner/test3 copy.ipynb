{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import ast\n",
    "from spacy.training.example import Example\n",
    "\n",
    "# load the training dataset\n",
    "import pandas as pd\n",
    "training_data_file_path = \"/Users/shubham/Desktop/ner.csv\"\n",
    "\n",
    "# read csv into pandas DataFrame\n",
    "df = pd.read_csv(training_data_file_path)\n",
    "# Grab any basic information df.head() or: Summary statistics, Access a specific column, etc...\n",
    "\n",
    "'''\n",
    "One thing to note here: is that this NER dataset that I found is split into the following columns:\n",
    "    - Sentence #, Sentence, POS(Word type description, NOUN, etc..), Tag(O-per with IOB-named entity)\n",
    "But spaCy doesn't understand the data in this format. spaCy understands data in the format of a tuple\n",
    "    - (string, dict) where dict = {entities : [tuples of (start, end, entity)]}\n",
    "So in order to train the model with spaCy like the paper suggests we first need to reformat the dataFrame to match\n",
    "into this form which is what taggedFormat(df) is doing\n",
    "'''\n",
    "def taggedFormat(df):\n",
    "    tagged_spacy_data = []\n",
    "    for index, row in df.iterrows():\n",
    "        sentence = row['Sentence']\n",
    "        ner_tags = row['Tag']\n",
    "\n",
    "        # right now here ner_tags is of type string, so in order to get the elements lets convert to a list\n",
    "        ner_tags = ast.literal_eval(ner_tags)\n",
    "\n",
    "        entities = []\n",
    "        start = 0\n",
    "        end = 0\n",
    "        for tagIndex, word in enumerate(sentence.split()):\n",
    "            end = start + len(word)\n",
    "\n",
    "            if tagIndex >= len(ner_tags): \n",
    "                break\n",
    "            if(ner_tags[tagIndex] != 'O'):\n",
    "                entities.append((start, end, ner_tags[tagIndex]))\n",
    "\n",
    "            start = end + 1\n",
    "        \n",
    "        if len(entities) > 0:\n",
    "            tagged_spacy_data.append((sentence, {\"entities\": entities}))\n",
    "\n",
    "    return tagged_spacy_data\n",
    "\n",
    "'''\n",
    "1st Function(taggedFormat(df)): gives you a line of output like this, ignoring the sentence part in the beginning:\n",
    "    - ({'entities': [(0, 4, 'B-gpe'), (12, 21, 'B-per'), (22, 29, 'I-per'), (30, 41, 'I-per'), (47, 54, 'B-tim'), (60, 68, 'B-gpe'), (100, 104, 'B-gpe'), (158, 165, 'B-gpe')]})\n",
    "\n",
    "2nd Function(combineTaggedData(tagged_spacy_data)): looking at the above example notice how (12, 41) are all B,I,I-per, they are talking about the same named entity PER, so we need to combine these somehow to turn it into this\n",
    "    - ({'entities': [(0, 4, 'B-gpe'), (12, 41, 'B-per???'), (47, 54, 'B-tim'), (60, 68, 'B-gpe'), (100, 104, 'B-gpe'), (158, 165, 'B-gpe')]})\n",
    "\n",
    "3rd Function. But when we make our training data we dont include the tags: 'B-', 'I-', etc.. and we also capitalize the 'per' -> 'PER' to follow a standard so we need to do some processing of this formatted data\n",
    "and put in this form(using .upper() and [2:] we can do this):\n",
    "    - {'entities': [(0, 4, 'GPE'), (12, 41, 'PER'), (47, 54, 'TIM'), (60, 68, 'GPE'), (100, 104, 'GPE'), (158, 165, 'GPE')]}\n",
    "\n",
    "This is one of the main techniques that the research paper proposes in the methodology section and how to extract sentence data to create a proper training data to build our model.\n",
    "Obviously in the paper they go directly from HTML to sentence parsing my usecase is a bit different since I am using a dataset from kaggle but the technique here is still the same.\n",
    "'''\n",
    "\n",
    "def combineTaggedData(tagged_spacy_data):\n",
    "    to_combine = []\n",
    "\n",
    "    for sentence, entities_dict in tagged_spacy_data:\n",
    "        entities_list = entities_dict[\"entities\"]\n",
    "\n",
    "        i = 0\n",
    "        j = 1\n",
    "        currArr = []\n",
    "        found = False\n",
    "        while j < len(entities_list):\n",
    "            start1, end1, entity_type1 = entities_list[i]\n",
    "            start2, end2, entity_type2 = entities_list[j]\n",
    "\n",
    "            splitI = entity_type1.split('-')\n",
    "            splitJ = entity_type2.split('-')\n",
    "\n",
    "            if splitI[0] == 'B' and splitJ[0] == 'I':\n",
    "                if j == len(entities_list) - 1:\n",
    "                    currArr.append((start1, end2, entity_type1))\n",
    "                    found = True\n",
    "                j += 1\n",
    "            else:\n",
    "                _, endPrev, _ = entities_list[j-1]\n",
    "                currArr.append((start1, endPrev, entity_type1))\n",
    "                i = j\n",
    "                j += 1\n",
    "        \n",
    "        if i == len(entities_list) - 1:\n",
    "            currArr.extend(entities_list[i:])\n",
    "\n",
    "        to_combine.append((sentence, {\"entities\" : currArr}))\n",
    "    \n",
    "    return to_combine\n",
    "\n",
    "def convertSpacyFormat(to_combine):\n",
    "    spacy_formatted_data = []\n",
    "\n",
    "    for sentence, entities_dict in to_combine:\n",
    "\n",
    "        entities_list = entities_dict[\"entities\"]\n",
    "        modified_entities = []\n",
    "\n",
    "        for start, end, type in entities_list:\n",
    "            currType = type\n",
    "            formattedType = currType[2:].upper() # take 'B-Geo' -> 'GEO'\n",
    "            modified_entities.append((start, end, formattedType))\n",
    "        \n",
    "        spacy_formatted_data.append((sentence, {\"entities\" : modified_entities}))\n",
    "\n",
    "    return spacy_formatted_data\n",
    "\n",
    "\n",
    "# Convert the DataFrame to spaCy format but still the tags are in there\n",
    "spacy_training_data = taggedFormat(df)\n",
    "# print(spacy_training_data[45][1])\n",
    "\n",
    "# remove the tags and now we are officially ready to train our model, spacy_formatted_data is a list of training data\n",
    "combined_spacy_data = combineTaggedData(spacy_training_data)\n",
    "# print(combined_spacy_data[45])\n",
    "# print(f\"{combined_spacy_data[10][0][12:21]}, {combined_spacy_data[10][0][22:29]}, {combined_spacy_data[10][0][30:41]}\")\n",
    "\n",
    "spacy_formatted_data = convertSpacyFormat(combined_spacy_data)\n",
    "# print(spacy_training_data[45][1])\n",
    "# print(combined_spacy_data[45])\n",
    "\n",
    "# print(spacy_training_data[6][1])\n",
    "# print(combined_spacy_data[6])\n",
    "\n",
    "# print(spacy_training_data[13][1])\n",
    "# print(combined_spacy_data[13])\n",
    "\n",
    "# print(spacy_training_data[1381][1])\n",
    "# print(combined_spacy_data[1381])\n",
    "\n",
    "# for rows in spacy_formatted_data:\n",
    "#     print(f\"{rows}\")\n",
    "\n",
    "# TESTING: make sure I get the right entities, types, etc...\n",
    "# for i in range(len(spacy_data)):\n",
    "#   print(spacy_data[i])\n",
    "# print(type(spacy_formatted_data))\n",
    "# for i in range(len(spacy_formatted_data)):\n",
    "#         print(spacy_formatted_data[i])\n",
    "# print(spacy_training_data[0])\n",
    "# print(spacy_training_data[0][0][48:54], spacy_training_data[0][0][77:81], spacy_training_data[0][0][111:118])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U.S. weather forecasters say Hurricane Wilma has strengthened to a powerful category 5 storm and a key low-pressure measurement indicates it is the most powerful storm of the year .\n",
      "Words: ['U.S.', 'weather', 'forecasters', 'say', 'Hurricane', 'Wilma', 'has', 'strengthened', 'to', 'a', 'powerful', 'category', '5', 'storm', 'and', 'a', 'key', 'low-pressure', 'measurement', 'indicates', 'it', 'is', 'the', 'most', 'powerful', 'storm', 'of', 'the', 'year', '.']\n",
      "Word Count: 30\n",
      "29\n",
      "(0, 4, B-geo | 0\n"
     ]
    }
   ],
   "source": [
    "def convert_to_spacy(df):\n",
    "    spacy_data = []\n",
    "    # for index, row in df.iterrows():\n",
    "    #     sentence = row['Sentence']\n",
    "    #     ner_tags = row['Tag']\n",
    "\n",
    "    #     # print(ner_tags)\n",
    "    #     # convert string -> list\n",
    "    #     ner_tags = ast.literal_eval(ner_tags)\n",
    "\n",
    "    #     # print(index, sentence)\n",
    "\n",
    "    sentence = df['Sentence'][47591]\n",
    "    print(sentence)\n",
    "\n",
    "    totalWords = sentence.split()\n",
    "    print(f\"Words: {totalWords}\")\n",
    "    print(f\"Word Count: {len(totalWords)}\")\n",
    "\n",
    "\n",
    "    ner_tags = df['Tag'][47591]\n",
    "    ner_tags = ast.literal_eval(ner_tags)\n",
    "    print(len(ner_tags))\n",
    "\n",
    "    entities = []\n",
    "    start = 0\n",
    "    end = 0\n",
    "    for tagIndex, word in enumerate(sentence.split()):\n",
    "        end = start + len(word)\n",
    "        if tagIndex >= len(ner_tags):\n",
    "            break\n",
    "        if(ner_tags[tagIndex] != 'O'):\n",
    "            print(f\"({start}, {end}, {ner_tags[tagIndex]} | {tagIndex}\")\n",
    "            entities.append((start, end, ner_tags[tagIndex]))\n",
    "\n",
    "        start = end + 1\n",
    "        \n",
    "\n",
    "        # entities.append((start, end, ner_tags[tagIndex])) if(ner_tags[tagIndex] != 'O')\n",
    "        \n",
    "\n",
    "    return spacy_data\n",
    "\n",
    "# Convert the DataFrame to spaCy format\n",
    "spacy_training_data = convert_to_spacy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Albert Einstein\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " was born on \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    March 14, 1879\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIM</span>\n",
       "</mark>\n",
       ", in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ulm\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO</span>\n",
       "</mark>\n",
       ", in the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Kingdom of Württemberg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    German\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " Empire. He made significant contributions to the field of theoretical physics, especially in the development of the theory of relativity. \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Einstein\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " received the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nobel Prize\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Physics\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1921\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIM</span>\n",
       "</mark>\n",
       " for his explanation of the photoelectric effect. He later moved to the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    United States\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO</span>\n",
       "</mark>\n",
       ", where he continued his scientific work and became a prominent figure in academia.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy.training.example import Example\n",
    "import random\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "sample_txt = \"Albert Einstein was born on March 14, 1879, in Ulm, in the Kingdom of Württemberg in the German Empire. He made significant contributions to the field of theoretical physics, especially in the development of the theory of relativity. Einstein received the Nobel Prize in Physics in 1921 for his explanation of the photoelectric effect. He later moved to the United States, where he continued his scientific work and became a prominent figure in academia.\"\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "ner = nlp.add_pipe(\"ner\")\n",
    "\n",
    "# midpoint = len(spacy_formatted_data) // 2\n",
    "# dataset1 = spacy_formatted_data[:midpoint]\n",
    "# dataset2 = spacy_formatted_data[midpoint:]\n",
    "\n",
    "collected_training_data = []\n",
    "for text, entity_map_item in spacy_formatted_data:\n",
    "    converted_data = Example.from_dict(nlp.make_doc(text), entity_map_item)\n",
    "    collected_training_data.append(converted_data)\n",
    "\n",
    "nlp.begin_training()\n",
    "for i in range(30):\n",
    "    random.shuffle(collected_training_data)\n",
    "    for data in collected_training_data:\n",
    "        nlp.update([data], drop=0.4)\n",
    "\n",
    "nlp.to_disk(\"custom_ner_model\")\n",
    "\n",
    "# Step 4: Test the Model\n",
    "custom_ner_modl = spacy.load(\"custom_ner_model\")\n",
    "doc = custom_ner_modl(sample_txt)\n",
    "\n",
    "# Render the visualization with custom colors\n",
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/shubham/NERChromeExtDemoTask2/mysite/myner/test3 copy.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shubham/NERChromeExtDemoTask2/mysite/myner/test3%20copy.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# for 30 it was 7 hours\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shubham/NERChromeExtDemoTask2/mysite/myner/test3%20copy.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# for 10 it was 2 hours\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shubham/NERChromeExtDemoTask2/mysite/myner/test3%20copy.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# custom_ner_modl = spacy.load(\"custom_ner_model\")\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/shubham/NERChromeExtDemoTask2/mysite/myner/test3%20copy.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m nlp\u001b[39m.\u001b[39mto_disk(\u001b[39m\"\u001b[39m\u001b[39mcustom_ner_model\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "# for 30 it was 7 hours\n",
    "# for 10 it was 2 hours\n",
    "# custom_ner_modl = spacy.load(\"custom_ner_model\")\n",
    "\n",
    "nlp.to_disk(\"custom_ner_model\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
