{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import ast\n",
    "from spacy.training.example import Example\n",
    "\n",
    "# load the training dataset\n",
    "import pandas as pd\n",
    "training_data_file_path = \"/Users/shubham/Desktop/ner.csv\"\n",
    "\n",
    "# read csv into pandas DataFrame\n",
    "df = pd.read_csv(training_data_file_path)\n",
    "# Grab any basic information df.head() or: Summary statistics, Access a specific column, etc...\n",
    "\n",
    "'''\n",
    "One thing to note here: is that this NER dataset that I found is split into the following columns:\n",
    "    - Sentence #, Sentence, POS(Word type description, NOUN, etc..), Tag(O-per with IOB-named entity)\n",
    "But spaCy doesn't understand the data in this format. spaCy understands data in the format of a tuple\n",
    "    - (string, dict) where dict = {entities : [tuples of (start, end, entity)]}\n",
    "So in order to train the model with spaCy like the paper suggests we first need to reformat the dataFrame to match\n",
    "into this form which is what taggedFormat(df) is doing\n",
    "'''\n",
    "def taggedFormat(df):\n",
    "    tagged_spacy_data = []\n",
    "    for index, row in df.iterrows():\n",
    "        sentence = row['Sentence']\n",
    "        ner_tags = row['Tag']\n",
    "\n",
    "        # right now here ner_tags is of type string, so in order to get the elements lets convert to a list\n",
    "        ner_tags = ast.literal_eval(ner_tags)\n",
    "\n",
    "        entities = []\n",
    "        start = 0\n",
    "        end = 0\n",
    "        for tagIndex, word in enumerate(sentence.split()):\n",
    "            end = start + len(word)\n",
    "\n",
    "            if tagIndex >= len(ner_tags): \n",
    "                break\n",
    "            if(ner_tags[tagIndex] != 'O'):\n",
    "                entities.append((start, end, ner_tags[tagIndex]))\n",
    "\n",
    "            start = end + 1\n",
    "        \n",
    "        if len(entities) > 0:\n",
    "            tagged_spacy_data.append((sentence, {\"entities\": entities}))\n",
    "\n",
    "    return tagged_spacy_data\n",
    "\n",
    "'''\n",
    "1st Function(taggedFormat(df)): gives you a line of output like this, ignoring the sentence part in the beginning:\n",
    "    - ({'entities': [(0, 4, 'B-gpe'), (12, 21, 'B-per'), (22, 29, 'I-per'), (30, 41, 'I-per'), (47, 54, 'B-tim'), (60, 68, 'B-gpe'), (100, 104, 'B-gpe'), (158, 165, 'B-gpe')]})\n",
    "\n",
    "2nd Function(combineTaggedData(tagged_spacy_data)): looking at the above example notice how (12, 41) are all B,I,I-per, they are talking about the same named entity PER, so we need to combine these somehow to turn it into this\n",
    "    - ({'entities': [(0, 4, 'B-gpe'), (12, 41, 'B-per???'), (47, 54, 'B-tim'), (60, 68, 'B-gpe'), (100, 104, 'B-gpe'), (158, 165, 'B-gpe')]})\n",
    "\n",
    "3rd Function. But when we make our training data we dont include the tags: 'B-', 'I-', etc.. and we also capitalize the 'per' -> 'PER' to follow a standard so we need to do some processing of this formatted data\n",
    "and put in this form(using .upper() and [2:] we can do this):\n",
    "    - {'entities': [(0, 4, 'GPE'), (12, 41, 'PER'), (47, 54, 'TIM'), (60, 68, 'GPE'), (100, 104, 'GPE'), (158, 165, 'GPE')]}\n",
    "\n",
    "This is one of the main techniques that the research paper proposes in the methodology section and how to extract sentence data to create a proper training data to build our model.\n",
    "Obviously in the paper they go directly from HTML to sentence parsing my usecase is a bit different since I am using a dataset from kaggle but the technique here is still the same.\n",
    "'''\n",
    "\n",
    "def combineTaggedData(tagged_spacy_data):\n",
    "    to_combine = []\n",
    "\n",
    "    for sentence, entities_dict in tagged_spacy_data:\n",
    "        entities_list = entities_dict[\"entities\"]\n",
    "\n",
    "        i = 0\n",
    "        j = 1\n",
    "        currArr = []\n",
    "        found = False\n",
    "        while j < len(entities_list):\n",
    "            start1, end1, entity_type1 = entities_list[i]\n",
    "            start2, end2, entity_type2 = entities_list[j]\n",
    "\n",
    "            splitI = entity_type1.split('-')\n",
    "            splitJ = entity_type2.split('-')\n",
    "\n",
    "            if splitI[0] == 'B' and splitJ[0] == 'I':\n",
    "                if j == len(entities_list) - 1:\n",
    "                    currArr.append((start1, end2, entity_type1))\n",
    "                    found = True\n",
    "                j += 1\n",
    "            else:\n",
    "                _, endPrev, _ = entities_list[j-1]\n",
    "                currArr.append((start1, endPrev, entity_type1))\n",
    "                i = j\n",
    "                j += 1\n",
    "        \n",
    "        if i == len(entities_list) - 1:\n",
    "            currArr.extend(entities_list[i:])\n",
    "\n",
    "        to_combine.append((sentence, {\"entities\" : currArr}))\n",
    "    \n",
    "    return to_combine\n",
    "\n",
    "def convertSpacyFormat(to_combine):\n",
    "    spacy_formatted_data = []\n",
    "\n",
    "    for sentence, entities_dict in to_combine:\n",
    "\n",
    "        entities_list = entities_dict[\"entities\"]\n",
    "        modified_entities = []\n",
    "\n",
    "        for start, end, type in entities_list:\n",
    "            currType = type\n",
    "            formattedType = currType[2:].upper() # take 'B-Geo' -> 'GEO'\n",
    "            modified_entities.append((start, end, formattedType))\n",
    "        \n",
    "        spacy_formatted_data.append((sentence, {\"entities\" : modified_entities}))\n",
    "\n",
    "    return spacy_formatted_data\n",
    "\n",
    "\n",
    "# Convert the DataFrame to spaCy format but still the tags are in there\n",
    "spacy_training_data = taggedFormat(df)\n",
    "# print(spacy_training_data[45][1])\n",
    "\n",
    "# remove the tags and now we are officially ready to train our model, spacy_formatted_data is a list of training data\n",
    "combined_spacy_data = combineTaggedData(spacy_training_data)\n",
    "# print(combined_spacy_data[45])\n",
    "# print(f\"{combined_spacy_data[10][0][12:21]}, {combined_spacy_data[10][0][22:29]}, {combined_spacy_data[10][0][30:41]}\")\n",
    "\n",
    "spacy_formatted_data = convertSpacyFormat(combined_spacy_data)\n",
    "# print(spacy_training_data[45][1])\n",
    "# print(combined_spacy_data[45])\n",
    "\n",
    "# print(spacy_training_data[6][1])\n",
    "# print(combined_spacy_data[6])\n",
    "\n",
    "# print(spacy_training_data[13][1])\n",
    "# print(combined_spacy_data[13])\n",
    "\n",
    "# print(spacy_training_data[1381][1])\n",
    "# print(combined_spacy_data[1381])\n",
    "\n",
    "# for rows in spacy_formatted_data:\n",
    "#     print(f\"{rows}\")\n",
    "\n",
    "# TESTING: make sure I get the right entities, types, etc...\n",
    "# for i in range(len(spacy_data)):\n",
    "#   print(spacy_data[i])\n",
    "# print(type(spacy_formatted_data))\n",
    "# for i in range(len(spacy_formatted_data)):\n",
    "#         print(spacy_formatted_data[i])\n",
    "# print(spacy_training_data[0])\n",
    "# print(spacy_training_data[0][0][48:54], spacy_training_data[0][0][77:81], spacy_training_data[0][0][111:118])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U.S. weather forecasters say Hurricane Wilma has strengthened to a powerful category 5Â storm and a key low-pressure measurement indicates it is the most powerful storm of the year .\n",
      "Words: ['U.S.', 'weather', 'forecasters', 'say', 'Hurricane', 'Wilma', 'has', 'strengthened', 'to', 'a', 'powerful', 'category', '5', 'storm', 'and', 'a', 'key', 'low-pressure', 'measurement', 'indicates', 'it', 'is', 'the', 'most', 'powerful', 'storm', 'of', 'the', 'year', '.']\n",
      "Word Count: 30\n",
      "29\n",
      "(0, 4, B-geo | 0\n"
     ]
    }
   ],
   "source": [
    "def convert_to_spacy(df):\n",
    "    spacy_data = []\n",
    "    # for index, row in df.iterrows():\n",
    "    #     sentence = row['Sentence']\n",
    "    #     ner_tags = row['Tag']\n",
    "\n",
    "    #     # print(ner_tags)\n",
    "    #     # convert string -> list\n",
    "    #     ner_tags = ast.literal_eval(ner_tags)\n",
    "\n",
    "    #     # print(index, sentence)\n",
    "\n",
    "    sentence = df['Sentence'][47591]\n",
    "    print(sentence)\n",
    "\n",
    "    totalWords = sentence.split()\n",
    "    print(f\"Words: {totalWords}\")\n",
    "    print(f\"Word Count: {len(totalWords)}\")\n",
    "\n",
    "\n",
    "    ner_tags = df['Tag'][47591]\n",
    "    ner_tags = ast.literal_eval(ner_tags)\n",
    "    print(len(ner_tags))\n",
    "\n",
    "    entities = []\n",
    "    start = 0\n",
    "    end = 0\n",
    "    for tagIndex, word in enumerate(sentence.split()):\n",
    "        end = start + len(word)\n",
    "        if tagIndex >= len(ner_tags):\n",
    "            break\n",
    "        if(ner_tags[tagIndex] != 'O'):\n",
    "            print(f\"({start}, {end}, {ner_tags[tagIndex]} | {tagIndex}\")\n",
    "            entities.append((start, end, ner_tags[tagIndex]))\n",
    "\n",
    "        start = end + 1\n",
    "        \n",
    "\n",
    "        # entities.append((start, end, ner_tags[tagIndex])) if(ner_tags[tagIndex] != 'O')\n",
    "        \n",
    "\n",
    "    return spacy_data\n",
    "\n",
    "# Convert the DataFrame to spaCy format\n",
    "spacy_training_data = convert_to_spacy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Albert Einstein\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " was born on \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    March 14, 1879\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIM</span>\n",
       "</mark>\n",
       ", in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ulm\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO</span>\n",
       "</mark>\n",
       ", in the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Kingdom of WÃ¼rttemberg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    German\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " Empire. He made significant contributions to the field of theoretical physics, especially in the development of the theory of relativity. \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Einstein\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " received the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nobel Prize\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Physics\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1921\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIM</span>\n",
       "</mark>\n",
       " for his explanation of the photoelectric effect. He later moved to the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    United States\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO</span>\n",
       "</mark>\n",
       ", where he continued his scientific work and became a prominent figure in academia.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy.training.example import Example\n",
    "import random\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "sample_txt = \"Albert Einstein was born on March 14, 1879, in Ulm, in the Kingdom of WÃ¼rttemberg in the German Empire. He made significant contributions to the field of theoretical physics, especially in the development of the theory of relativity. Einstein received the Nobel Prize in Physics in 1921 for his explanation of the photoelectric effect. He later moved to the United States, where he continued his scientific work and became a prominent figure in academia.\"\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "ner = nlp.add_pipe(\"ner\")\n",
    "\n",
    "# midpoint = len(spacy_formatted_data) // 2\n",
    "# dataset1 = spacy_formatted_data[:midpoint]\n",
    "# dataset2 = spacy_formatted_data[midpoint:]\n",
    "\n",
    "collected_training_data = []\n",
    "for text, entity_map_item in spacy_formatted_data:\n",
    "    converted_data = Example.from_dict(nlp.make_doc(text), entity_map_item)\n",
    "    collected_training_data.append(converted_data)\n",
    "\n",
    "nlp.begin_training()\n",
    "for i in range(30):\n",
    "    random.shuffle(collected_training_data)\n",
    "    for data in collected_training_data:\n",
    "        nlp.update([data], drop=0.4)\n",
    "\n",
    "nlp.to_disk(\"custom_ner_model\")\n",
    "\n",
    "# Step 4: Test the Model\n",
    "custom_ner_modl = spacy.load(\"custom_ner_model\")\n",
    "doc = custom_ner_modl(sample_txt)\n",
    "\n",
    "# Render the visualization with custom colors\n",
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1, 'PERSON'), (3, 4, 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from collections import defaultdict\n",
    "\n",
    "texts = [\"John works at Microsoft.\"]\n",
    "\n",
    "# Number of alternate analyses to consider. More is slower, and not necessarily better -- you need to experiment on your problem.\n",
    "beam_width = 16\n",
    "\n",
    "# This clips solutions at each step. \n",
    "# We multiply the score of the top-ranked action by this value, and use the result as a threshold.\n",
    "# This prevents the parser from exploring options that look very unlikely, saving a bit of efficiency. \n",
    "# Accuracy may also improve, because we've trained on greedy objective.\n",
    "beam_density = 0.0001 \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "docs = list(nlp.pipe(texts))\n",
    "beams = nlp.get_pipe('ner').beam_parse(docs, beam_width=beam_width, beam_density=beam_density)\n",
    "\n",
    "# Calculate entity scores\n",
    "entity_scores = defaultdict(float)\n",
    "for doc, beam in zip(docs, beams):\n",
    "    for score, ents in nlp.get_pipe('ner').moves.get_beam_parses(beam):\n",
    "        total_score = score\n",
    "        print(ents)\n",
    "        for start, end, label in ents:\n",
    "            entity_scores[(start, end, label)] += score / total_score\n",
    "\n",
    "# # Print entity scores\n",
    "# for key, score in entity_scores.items():\n",
    "#     print(f'Entity: {key}, Score: {score}')\n",
    "\n",
    "# # # Calculate the total sum of probabilities\n",
    "# total_prob_sum = sum(entity_scores.values())\n",
    "# print(total_prob_sum)\n",
    "\n",
    "# # # Normalize entity scores\n",
    "# normalized_entity_scores = {key: prob / total_prob_sum for key, prob in entity_scores.items()}\n",
    "# print(normalized_entity_scores)\n",
    "\n",
    "# # Convert to a list of dictionaries\n",
    "# entity_probabilities = [{'start': start, 'end': end, 'label': label, 'prob': prob}\n",
    "#                         for (start, end, label), prob in normalized_entity_scores.items()]\n",
    "\n",
    "# # Sort and print the normalized results\n",
    "# for entity in sorted(entity_probabilities, key=lambda x: x['start']):\n",
    "#     print(entity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    John\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " works at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy.training.example import Example\n",
    "import random\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "texts = 'John works at Microsoft.'\n",
    "custom_ner_modl = spacy.load(\"en_core_web_sm\")\n",
    "doc = custom_ner_modl(texts)\n",
    "displacy.render(doc, style='ent')\n",
    "\n",
    "\n",
    "\n",
    "# sample_txt = \"Albert Einstein was born on March 14, 1879, in Ulm, in the Kingdom of WÃ¼rttemberg in the German Empire. He made significant contributions to the field of theoretical physics, especially in the development of the theory of relativity. Einstein received the Nobel Prize in Physics in 1921 for his explanation of the photoelectric effect. He later moved to the United States, where he continued his scientific work and became a prominent figure in academia.\"\n",
    "\n",
    "\n",
    "# custom_ner_modl = spacy.load(\"custom_ner_model\")\n",
    "# doc = custom_ner_modl(sample_txt)\n",
    "\n",
    "# # Render the visualization with custom colors\n",
    "# displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1, 'PERSON'), (3, 4, 'ORG')]\n",
      "Entity: (0, 4, 'ORG'), Score: 1.0\n",
      "Entity: (14, 23, 'ORG'), Score: 1.0\n",
      "2.0\n",
      "{(0, 4, 'ORG'): 0.5, (14, 23, 'ORG'): 0.5}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from collections import defaultdict\n",
    "\n",
    "text = \"John works at Microsoft.\"\n",
    "\n",
    "# Number of alternate analyses to consider. More is slower, and not necessarily better -- you need to experiment on your problem.\n",
    "beam_width = 16\n",
    "\n",
    "# This clips solutions at each step.\n",
    "# We multiply the score of the top-ranked action by this value, and use the result as a threshold.\n",
    "# This prevents the parser from exploring options that look very unlikely, saving a bit of efficiency.\n",
    "# Accuracy may also improve, because we've trained on greedy objective.\n",
    "beam_density = 0.0001\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp(text)\n",
    "beams = nlp.get_pipe('ner').beam_parse([doc], beam_width=beam_width, beam_density=beam_density)\n",
    "\n",
    "# Calculate entity scores\n",
    "entity_scores = defaultdict(float)\n",
    "\n",
    "for beam in beams:\n",
    "    for score, ents in nlp.get_pipe('ner').moves.get_beam_parses(beam):\n",
    "        total_score = score\n",
    "        print(ents)\n",
    "        for ents in doc.ents:\n",
    "            entity_scores[(ents.start_char, ents.end_char, label)] += score / total_score\n",
    "\n",
    "# # Print entity scores\n",
    "# for (start, end, label), score in entity_scores.items():\n",
    "#     print(f'Entity: {label}, Start Char: {start}, End Char: {end}, Score: {score}')\n",
    "\n",
    "# Print entity scores\n",
    "for key, score in entity_scores.items():\n",
    "    print(f'Entity: {key}, Score: {score}')\n",
    "\n",
    "# # Calculate the total sum of probabilities\n",
    "total_prob_sum = sum(entity_scores.values())\n",
    "print(total_prob_sum)\n",
    "\n",
    "# # Normalize entity scores\n",
    "normalized_entity_scores = {key: prob / total_prob_sum for key, prob in entity_scores.items()}\n",
    "print(normalized_entity_scores)\n",
    "\n",
    "# # Convert to a list of dictionaries\n",
    "# entity_probabilities = [{'start': start, 'end': end, 'label': label, 'prob': prob}\n",
    "#                         for (start, end, label), prob in normalized_entity_scores.items()]\n",
    "\n",
    "# # Sort and print the normalized results\n",
    "# for entity in sorted(entity_probabilities, key=lambda x: x['start']):\n",
    "#     print(entity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'PER', 'start': 0, 'end': 7, 'score': 1.0}, {'label': 'ORG', 'start': 77, 'end': 83, 'score': 1.0}, {'label': 'GEO', 'start': 85, 'end': 92, 'score': 1.0}, {'label': 'ORG', 'start': 162, 'end': 168, 'score': 1.0}, {'label': 'GEO', 'start': 170, 'end': 177, 'score': 1.0}, {'label': 'ORG', 'start': 247, 'end': 253, 'score': 1.0}, {'label': 'GEO', 'start': 255, 'end': 262, 'score': 1.0}, {'label': 'ORG', 'start': 332, 'end': 338, 'score': 1.0}]]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from collections import defaultdict\n",
    "\n",
    "text = \"Shubham is a really cool guy who loves to eat apples and he likes to work at Google. Shubham is a really cool guy who loves to eat apples and he likes to work at Google. Shubham is a really cool guy who loves to eat apples and he likes to work at Google. Shubham is a really cool guy who loves to eat apples and he likes to work at Google.\"\n",
    "beam_width = 16\n",
    "beam_density = 0.0001\n",
    "\n",
    "custom_ner_model_path = \"/Users/shubham/ForwardDataLabTask1/task2_my_custom_ner_modelV2\"\n",
    "nlp = spacy.load(custom_ner_model_path)\n",
    "\n",
    "doc = nlp(text)\n",
    "beams = nlp.get_pipe('ner').beam_parse([doc], beam_width=beam_width, beam_density=beam_density)\n",
    "\n",
    "# Calculate entity scores\n",
    "entityScore = []\n",
    "currEntityScore = []\n",
    "\n",
    "for beam in beams:\n",
    "    for score, ents in nlp.get_pipe('ner').moves.get_beam_parses(beam):\n",
    "        for ent in doc.ents:\n",
    "            ent_info = {'label' : ent.label_, 'start' : ent.start_char, 'end' : ent.end_char, 'score': score}\n",
    "            currEntityScore.append(ent_info)\n",
    "\n",
    "entityScore.append(currEntityScore)\n",
    "print(entityScore)\n",
    "\n",
    "# print(entityScore[0]['entities'])\n",
    "\n",
    "# # Print entity scores\n",
    "# for key, score in entity_scores.items():\n",
    "#     print(f'Entity: {key}, Score: {score}')\n",
    "\n",
    "# print(entities)\n",
    "\n",
    "# # # Calculate the total sum of probabilities\n",
    "# total_prob_sum = sum(entity_scores.values())\n",
    "# print(total_prob_sum)\n",
    "\n",
    "# # # Normalize entity scores\n",
    "# normalized_entity_scores = {key: prob / total_prob_sum for key, prob in entity_scores.items()}\n",
    "# print(normalized_entity_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes exactly 2 positional arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text, annotations \u001b[38;5;129;01min\u001b[39;00m train_data:\n\u001b[1;32m     15\u001b[0m     doc \u001b[38;5;241m=\u001b[39m nlp\u001b[38;5;241m.\u001b[39mmake_doc(text)\n\u001b[0;32m---> 16\u001b[0m     gold \u001b[38;5;241m=\u001b[39m Example(doc, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mannotations)\n\u001b[1;32m     17\u001b[0m     loss, scores \u001b[38;5;241m=\u001b[39m nlp\u001b[38;5;241m.\u001b[39mupdate([gold\u001b[38;5;241m.\u001b[39mdoc], [gold], drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Access scores for each token\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/training/example.pyx:79\u001b[0m, in \u001b[0;36mspacy.training.example.Example.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes exactly 2 positional arguments (1 given)"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.training import Example\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Example training data\n",
    "train_data = [\n",
    "    (\"Apple is a company.\", {'entities': [(0, 5, 'ORG')]})\n",
    "]\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):  # Adjust the number of epochs as needed\n",
    "    for text, annotations in train_data:\n",
    "        doc = nlp.make_doc(text)\n",
    "        gold = Example(doc, **annotations)\n",
    "        loss, scores = nlp.update([gold.doc], [gold], drop=0.5)\n",
    "\n",
    "        # Access scores for each token\n",
    "        for token, score_dict in zip(doc, scores):\n",
    "            print(f\"Token: {token.text}, Entity Scores: {score_dict}\")\n",
    "\n",
    "# Now you can access the entity scores during training for each token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Shubham\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " is a really cool guy who loves to eat apples and he likes to work at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Shubham\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO</span>\n",
       "</mark>\n",
       " is a really cool guy who loves to eat apples and he likes to work at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Shubham\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO</span>\n",
       "</mark>\n",
       " is a really cool guy who loves to eat apples and he likes to work at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Shubham\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO</span>\n",
       "</mark>\n",
       " is a really cool guy who loves to eat apples and he likes to work at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy.training.example import Example\n",
    "import random\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "text = \"Shubham is a really cool guy who loves to eat apples and he likes to work at Google. Shubham is a really cool guy who loves to eat apples and he likes to work at Google. Shubham is a really cool guy who loves to eat apples and he likes to work at Google. Shubham is a really cool guy who loves to eat apples and he likes to work at Google.\"\n",
    "custom_ner_model_path = \"/Users/shubham/ForwardDataLabTask1/task2_my_custom_ner_modelV2\"\n",
    "nlp = spacy.load(custom_ner_model_path)\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style='ent')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
